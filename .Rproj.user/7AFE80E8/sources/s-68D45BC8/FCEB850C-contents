library(caret)
library(reshape2)

setwd("E:/BC_wildfires")


##################### Read ground plot data and ALS metrics ################


plotLoc <- readOGR("E:/BC_wildfires/Imputation/plotsLocation.shp")
plotLoc <- as.data.frame(plotLoc)
plotLoc$file_name <- as.character(plotLoc$file_name)

pull = matrix(unlist(strsplit(plotLoc$file_name,'\\_|\\.')),length(plotLoc$file_name),5,byrow = T)
plot_id = paste(pull[,2],'_',pull[,4],sep="")

plot_id[68:291] <- plotLoc$PLOT_ID[68:291]

plotLoc$PLOT_ID <-  NULL
plotLoc$file_name <- NULL
plotLoc$coords.x3 <- NULL
plotLoc$Plot_ID <- plot_id

colnames(plotLoc) <- c("X","Y","Plot_ID")

#AFRF

af_att <- read.csv("./AFRF/Plots/AFRF_plot_data_reworked_2017.csv",header = TRUE)
af_att <- af_att[,c("Plot_ID","Loreys_Height","ba_ha..m2.ha.","vol_ha..m3.ha.")]
colnames(af_att) <- c("Plot_ID","lor","ba","vol")
af_att$Plot_ID <- as.character(af_att$Plot_ID)

#Load metrics

af_met <- read.csv("./AFRF/ALS_metrics/AFRF_metrics_lastools.csv",header = TRUE)
af_met$file_name <- as.character(af_met$file_name)
split_name<- strsplit(substr(af_met$file_name,75,nchar(af_met$file_name)),"\\_|\\.")
plot_ID = vector("character")

for (k in 1:nrow(af_met)) {
  plot_ID[k] = paste(split_name[[k]][2],split_name[[k]][4],sep="_")
}

af_met$Plot_ID <- plot_ID
af_met$file_name <- NULL


selectMetrics <- c("avg","p50","p95","cov_gap","std","kur")
af_met <- af_met[,c("Plot_ID",selectMetrics)]

af_all <- merge(af_att,af_met,by="Plot_ID")

af_all$site <- "AFRF"

rm(af_met,af_att,split_name)
# Kamloops

kam_all <- read.csv("./Kamloops/ALS_metrics/kam_plots_newmetrics.csv",header=TRUE)
kam_all <- kam_all[kam_all$p95 != -9999,] #Remove plots without ALS metrics

selectMetrics <- c("avg","p50","p95","cov_gap","std","kur")
colOfInterest <- c("PLOT_ID","BA_HA","ht_lor_l","vht_wsv","vht_wsvd",selectMetrics)

kam_all <- kam_all[,colOfInterest]

kam_all <- kam_all[complete.cases(kam_all),] #Remove rows with NA values

kam_all$vol <- kam_all$vht_wsv + kam_all$vht_wsvd
kam_all$vht_wsv <- NULL
kam_all$vht_wsvd <- NULL
colnames(kam_all) <-c("Plot_ID","ba","lor", selectMetrics,"vol")

attNames <- c("lor","ba","vol")

kam_all <- kam_all[,c("Plot_ID",attNames,selectMetrics)]
kam_all$site <- "Kamloops"


#Okanagan

oka_all <- read.csv("./Okanagan/ALS_metrics/oka_plots_newmetrics.csv",header=TRUE)
oka_all <- oka_all[oka_all$p95 != -9999,] #Remove plots without ALS metrics

oka_all <- oka_all[,colOfInterest]

oka_all <- oka_all[complete.cases(oka_all),] #Remove rows with NA values

oka_all$vol <- oka_all$vht_wsv + oka_all$vht_wsvd
oka_all$vht_wsv <- NULL
oka_all$vht_wsvd <- NULL
colnames(oka_all) <-c("Plot_ID","ba","lor", selectMetrics,"vol")

oka_all <- oka_all[,c("Plot_ID",attNames,selectMetrics)]

oka_all$site <- "Okanagan"


############# Combine al data in one table ###################
opt <- "all"

if (opt =="AFRF") {
  theTable <- rbind(af_all)
}else if (opt == "Kamloops") {
  theTable <- rbind(kam_all)
}else if (opt == "Okanagan") {
  theTable <- rbind(oka_all)
}else if (opt == "all") {
  theTable <- rbind(af_all,kam_all,oka_all)
}else if (opt =='Kamloops Okanagan') {
  theTable <- rbind(kam_all,oka_all)
}

theTable$cov_gap <- (1-theTable$cov_gap)*100
colnames(theTable)[colnames(theTable)=="cov_gap"] <- "cov"

attNames <- c("lor","ba","vol")
selectMetrics <- c("avg","p50","p95","cov","std","kur")

theTable <- theTable[complete.cases(theTable),] #Remove NA
rowsub <- apply(theTable[,c(attNames,selectMetrics)],1,function(row) !(0%in%row)) #Remove 0
theTable <- theTable[rowsub,]


#Add dominant species column

species_plots <- read.csv("E:/BC_wildfires/species_plots.csv")

theTable <- merge(theTable,species_plots,by=c("Plot_ID","site"))


##############################################################

############ Data exploration ##############################

#Correlation of attributes and metrics
corr <- round(cor(theTable[,-c(1,11)]),1)
ggcorrplot(corr,hc.order=TRUE, type="lower", lab=TRUE)

ggplot(melt(theTable),aes(y=value)) + geom_boxplot(width=0.5)  +facet_wrap(.~variable , scales = "free")


#Remove plot_ID 19 in Okanagan
theTable <- theTable[!(theTable$site == "Okanagan" & theTable$Plot_ID == "19"),]

#Removing all outliers

removeOutlier = FALSE
removeLowCover = FALSE
removeLowCOverValue = 20 #Threshold under which cover values are filtered out [%]
bySpecies = FALSE
bySpeciesValue = "Bl"


if(removeOutlier){
  outlier <- logical(length = nrow(theTable))
  outlier <- outlier + ((theTable$lor > quantile(theTable$lor,0.75) + 1.5*IQR(theTable$lor))|(theTable$lor < quantile(theTable$lor,0.25) - 1.5*IQR(theTable$lor)))
  outlier <- outlier + ((theTable$ba > quantile(theTable$ba,0.75) + 1.5*IQR(theTable$ba))|(theTable$ba < quantile(theTable$ba,0.25) - 1.5*IQR(theTable$ba)))
  outlier <- outlier + ((theTable$vol > quantile(theTable$vol,0.75) + 1.5*IQR(theTable$vol))|(theTable$vol < quantile(theTable$vol,0.25) - 1.5*IQR(theTable$vol)))
  outlier <- outlier>0
  theTable <- theTable[!outlier,]
}

if(removeLowCover){
  theTable <- theTable[theTable$cov>20,]
}

if (bySpecies) {
  theTable <- theTable[theTable$dom_spec==bySpeciesValue,]
  }

#theTable <- theTable[theTable$ba<quantile(theTable$ba,0.75) + 1.5*IQR(theTable$ba),]

logTable <- theTable
logTable[,c(attNames,selectMetrics)] <- log(logTable[,c(attNames,selectMetrics)])

############ Model selection #################################

#Log transformed linear model

#Stepwise predictor selection

attNames <- c("lor","ba","vol")
selectMetrics <- c("avg","p50","p95","cov","std","kur")
maxVar <- c(length(selectMetrics),length(selectMetrics),length(selectMetrics))

for (a in 1:length(attNames)){ #length(attNames)
  attribute = attNames[a]
  selectVar = '1' #We start the regression without any predictor
  signif = TRUE #Boolean to check if we can add more sinificant predictors to the model
  varNb = 0

  while (signif == TRUE && varNb <= maxVar[a]) { #Do while there are significant predictors to add and the max number of predictors has not been reached
    statement_lm = paste0(attribute,"_lm <- lm(",attribute,"~",selectVar,",data=logTable)")
    eval(parse(text = statement_lm))
    eval(parse(text = paste0("print(summary(",attribute,"_lm)$adj.r.squared)")))
    statement_add = paste0("addVar = add1(",attribute,"_lm,~ ", paste(selectMetrics,collapse = " + "),",data=logTable,test='F')")
    eval(parse(text = statement_add))
    theMostSign = addVar[which.min(addVar$`Pr(>F)`),]
    if (theMostSign$`Pr(>F)` < 0.05) { #Is it a significant predictor ?
      selectVar = paste(selectVar,row.names(theMostSign),sep = ' + ')
      varNb = varNb + 1 #1 more predictor included in the model
    }else{ #There is no more significant variable
      signif = FALSE
    }
  }
}

print(lor_lm$call$formula)
print(ba_lm$call$formula)
print(vol_lm$call$formula)

#Backtransforming log variables

fit_lm <- data.frame(Plot_ID = theTable$Plot_ID)

for (a in 1:length(attNames)) {
  att <- attNames[a]
  eval(parse(text=paste0("logPred <- predict(",att,"_lm)")))
  n <- nrow(logTable)
  eval(parse(text=paste0("SEE <- (sum((logTable[,'",att,"'] - logPred)^2)/(n-2))^.5")))
  CF <- exp((SEE^2)/2)
  eval(parse(text=paste0("fit_lm$",att,"<-exp(logPred)*CF")))
}

#Random forest algorithm

attNames <- c("lor","ba","vol")
selectMetrics <- c("avg","p50","p95","cov","std","kur")

for (a in 1:length(attNames)){
  att <- attNames[a]
  form <- paste(selectMetrics,collapse='+')
  eval(parse(text=paste0(att,"_rf","<- randomForest(",att," ~ ",form,",data=theTable,importance=TRUE)")))
  }


################################################################################################

predict_models <- data.frame()
#colnames(predictlogTable) <- c("var","obs","pred","site")

for(a in 1:length(attNames)) {
  att <- attNames[a]
  eval(parse(text=paste0("model_loglm <- ",att,"_lm")))
  eval(parse(text=paste0("model_rf <- ",att,"_rf")))
  predict_models<- rbind(predict_models, data.frame(Plot_ID=theTable$Plot_ID,
                                                  var=att,
                                                  obs=theTable[,att],
                                                  log_lm=fit_lm[,att],
                                                  rf = predict(model_rf),
                                                  site=logTable$site))
}

theStats <- predict_models %>%
  dplyr::group_by(var,site) %>%
  dplyr::summarise(count = n(),
                  r2_loglm = R2(log_lm,obs),
                   rmse_loglm = RMSE(log_lm,obs)/mean(obs)*100,
                   bias_loglm = (1/count) * sum(log_lm - obs) / mean(obs)*100,
                   r2_rf = R2(rf,obs),
                   rmse_rf =RMSE(rf,obs)/mean(obs)*100,
                  bias_rf = (1/count) * sum(rf - obs) / mean(obs)*100)
theStats <- data.frame(theStats)
allStats <- predict_models %>%
  dplyr::group_by(var) %>%
  dplyr::summarise(count = n(),
                   r2_loglm = R2(log_lm,obs),
                   rmse_loglm = RMSE(log_lm,obs)/mean(obs)*100,
                   bias_loglm = (1/count) * sum(log_lm - obs) / mean(obs)*100,
                   r2_rf = R2(rf,obs),
                   rmse_rf =RMSE(rf,obs)/mean(obs)*100,
                   bias_rf = (1/count) * sum(rf - obs) / mean(obs)*100)
allStats <- data.frame(allStats)
allStats$site <- "All"


theStats <- rbind(theStats,allStats)

res <- data.frame(Plot_ID=theTable$Plot_ID,
                  site=theTable$site,
                  res_lm = predict_models$log_lm-predict_models$obs,
                  res_rf = predict_models$rf - predict_models$obs)

res <- merge.data.frame(res,plotLoc,by="Plot_ID")
coordinates(res) <- c("X","Y")

######### Cross-validation #############

#We randomly divide the data in k folds, giving us training and testing set

#Set number of folds
nFolds = 5

trainIndex <- createFolds(theTable$lor,k=nFolds,returnTrain=T)
testIndex <- lapply(trainIndex, function(x) setdiff(seq_len(nrow(theTable)),x))

train_control <- trainControl(method="cv",
                              number=nFolds,
                              returnData = TRUE,
                              savePredictions = TRUE,
                              index=trainIndex)




#Cross validation ONLY work with k-fold cross validation (without repetition)

predict_kfold <- data.frame()

for (a in attNames) {
  #Lm on log transformed variables
  eval(parse(text=paste0(a,"_lm_kfold <- train(formula(",a,"_lm),data=logTable, trControl = train_control, method='lm')")))
  eval(parse(text=paste0("model <-",a,"_lm_kfold")))
  logPred <- setorder(model$pred,rowIndex)
  n <- nrow(logPred)
  SEE <- (sum((logPred$obs-logPred$pred)^2)/(n-2))^.5
  CF <- exp((SEE^2)/2)
  lm_fit <- exp(logPred$pred)*CF

   #RF
  eval(parse(text=paste0(a,"_rf_kfold <- train(",a,"~ avg+p50+p95+cov+std+kur,data=theTable, trControl=train_control,method='rf')")))
  eval(parse(text=paste0("model <-",a,"_rf_kfold")))
  rfPred <- setorder(model$pred,rowIndex)
  rfPred <- rfPred[rfPred$mtry == model$bestTune$mtry,]

  predict_kfold <- rbind(predict_kfold,data.frame(Plot_ID=theTable$Plot_ID,
                         var=a,
                         obs=theTable[,a],
                         lm_kfold = lm_fit,
                         rf_kfold = rfPred$pred,
                         site = theTable$site))
}


allStats_kfold <- predict_kfold %>%
  dplyr::group_by(var) %>%
  dplyr::summarise(count = n(),
                   r2_lm_kfold = R2(lm_kfold,obs),
                   rmse_lm_kfold = RMSE(lm_kfold,obs)/mean(obs)*100,
                   bias_lm_kfold = (1/count) * sum(lm_kfold - obs) / mean(obs)*100,
                   r2_rf_kfold = R2(rf_kfold,obs),
                   rmse_rf_kfold =RMSE(rf_kfold,obs)/mean(obs)*100,
                   bias_rf_kfold = (1/count) * sum(rf_kfold - obs) / mean(obs)*100)
allStats_kfold <- data.frame(allStats_kfold)
allStats_kfold$site <- "All"

##################### Outputs and plots ##################

p <- ggplot(data = filter(predict_models,var=="lor"), aes(x=obs,y=rf,color=site)) +
  geom_point() +
  coord_fixed(ratio = 1) +
  geom_abline(slope=1,intercept = 0,size=1,colour='black',linetype=2) +
  theme_bw()
p


write.csv(dplyr::filter(predict_models,var=="lor"),"predict_models_lor.csv")



