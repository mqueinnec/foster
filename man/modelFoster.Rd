% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/modelFoster.R
\name{modelFoster}
\alias{modelFoster}
\title{Train a kNN (or regression model) from reponse variables (Y) and predictors (X) at reference location}
\usage{
modelFoster(x, y, inTrain = NULL, inVal = NULL, k = 1,
  method = "randomForest", ntree = 200, mtry = NULL, folds = 5)
}
\arguments{
\item{x}{A matrix or dataframe of predictors variables X for reference observations.
row names of X are identification of observations
X cannot contain missing values}

\item{y}{A matrix or dataframe of response variables Y for the reference observations.
row names of Y are identification of reference observations}

\item{k}{Numeric. Number of nearest neighbors}

\item{method}{Character. Type of model used for the imputation. Currently supports k-NN only}

\item{folds}{Numeric. Number of folds in \code{k-fold} CV}

\item{type}{Character. Type of distance metric ('euclidean','randomForest' etc.) if method='kNN'}

\item{crossValidation}{Character. Type of cross validation used : \code{"holdout","loocv","kfold","none"}}

\item{fracTrain}{Numeric. Fraction of observations used for training in \code{holdout} CV}

\item{finalModel}{Character. "All" returns model trained on all the dataset. Cross validation models are discarded
because they are only here to estimate the accuracy to predict unseen data. "CV" returns the model trained during the
CV. If multiple models are trained (e.g. k-fold), the best one (lowest average RMSE) is returned.}

\item{...}{Additional arguments to control kNN method and type (e.g. ntree, mtry)}
}
\value{
predicted Y variables at targets
}
\description{
Train a kNN (or regression model) from reponse variables (Y) and predictors (X) at reference location
}
