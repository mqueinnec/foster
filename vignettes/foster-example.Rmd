---
title: "Imputing forest attributes with FOSTER"
author: "Martin Queinnec"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{foster-example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=12, 
  fig.height=8,
  out.width="100%")
library(foster)
library(ggplot2)
library(raster)
library(knitr)
set.seed(1234)
  
```

##Introduction 

The goal of this vignette is to illustrate how FOSTER can be used to impute ALS-derived forest variables (response variables **Y**) to a larger area covered by multispectral satellite imagery and topographic data (predictor variables **X**). We can usually describe an imputation problem by defining two sets of observations: the reference and the target observations. At reference observations, both Y and X variables are defined while only X variables are available at targets. Ultimately, targets are the area where we want to impute response variables. 


FOSTER has been designed around the following workflow: 

* Data preprocessing to match the extent and spatial resolution of input data, mask cells that won't be included in the analysis or perform spatial filtering to smooth the data before main processing
* Perform a stratified random sampling to select cells that will be used to train and assess the accuracy of the k-NN model
* Calculate spectral indices from multispectral data and summarize time series of spectral indices at both references and targets 
* Divide the stratified random sample into training and validation sets
* Train a k-NN model from the training set and assess its accuracy with the validation set
* Impute response variables from the training set to the targets


```{r, echo=FALSE, out.width='100%'}
knitr::include_graphics(system.file("extdata/workflow/diagram_foster_compact_v2.png",package="foster"))
```

##Using FOSTER

### Load packages
In order to use the functions of FOSTER directly we need to attach the package using `library()`. Otherwise the functions need to be called explicitly from foster namespace using `foster::function_name()`. The `raster` package is regularly used throughout the workflow to read data using the functions `raster`, `stack` or `brick` (see below). It is therefore recommended attach the `raster` package as well. 

```{r}
library(foster)
library(raster)
```

### Main functions implemented in FOSTER

#### Data preparation
* `matchExtent`: match the extent of a raster from a reference. Cells of the reference having a specific value can be masked in the output raster object. 
* `matchResolution`: successively project and resample a raster coordinate system and spatial resolution to the ones of a reference raster. The input layer keeps its original extent instead of inheriting from the reference. 
* `focalMultiband`: apply a spatial filter (function) in the neighborhood of each cell. 
* `edges`: assign NA values to cell located in the neighborhood of other cells having NA values. This can be used for example to avoid sampling cells located close to borders. 
* `tile`: split a raster into smaller tiles. Can be used to reduce the size of data to be processed at a time and avoid memory issues. 

#### Stratified random sampling: 

* `getSample`: perform a k-means clustering of a raster and randomly sample cells within each cluster proportionally to the presence of those clusters across the entire raster
* `getSampleValues`: extract the values of a raster at sample points 

#### Calculate spectral indices and time series-based metrics
These functions supports both raster and point features to calculate wall-to-wall predictor variables or only at sample locations

* `calcIndices`: calculate a set of spectral indices from multispectral data
* `temporalMetrics`: summarize variables time series in a few metrics (e.g. mean, median, slope, IQR) 

#### Train a k-NN model and assess its accuracy 

* `partition`: split samples into training and testing sets
* `findNN`: train a k-NN model from the training sets and use the trained model to impute the Y variables on the testing set. Also returns the model accuracy by comparing observed and imputed response variables from the testing set
* `accuracy`: compute accuracy metrics from observed and predicted variables
* `scatter` : create a scatterplot between observed and predicted variables
* `varImp`: return the importance of each predictor variable if random forest is used to calculate the nearest neighbors

#### Impute response variables at targets

* `predictTrgs`: impute response variables from a trained k-NN model and predictor variables at targets.

### Data types
Two types of data are encountered when using FOSTER: rasters for wall-to-wall variables and vectors for variables extracted at sample points (point features). 

### Reading data from disk

#### Raster data

If the raster contains a single layer it can be read with `raster()` to create a `RasterLayer` object . However, if it is a multiband raster, `stack()` (`RasterStack`) or `brick()` (`RasterBrick`) should be used. `RasterBrick` are usually more efficient to process but they can only point to a single file while `RasterStack` can be assembled of layers from different file sources. `RasterStack` objects can also be created from multiple `RasterLayer` objects. 
The functions `raster`, `stack` and `brick` take the filename (full path to file or relative path from your current working directory) of the raster as an argument. Please refer to the documentation of these functions to learn more about the various options and file types supported by the raster package. 

```{r}
#Read single layer raster
elev_p95 <- raster(system.file("extdata/inputs/lidar/p95_lines_small.tif",package="foster"))
#Read muli-layer raster
spectral_1984 <- stack(system.file("extdata/inputs/spectral/Mosaic_SRef_UTM10S_1984_proxy_v2.tif",package="foster"))
```
 
#### Vector data
In order to read a shapefile from a file on disk we use `readOGR` from `rgdal` package, providing the directory where the file is located in `dsn` and the name of the layer without the `.shp` extension. Please refer to the documentation of rgdal for supported file type and other options. The data will be stored in a `SpatialPointsDataFrame` object. 

```{r}
dem_samples <- rgdal::readOGR(dsn = system.file("extdata/inputs/ref_table/",package = "foster"), layer = "dem_sample",verbose=F)
```

### Write data to disk

#### Raster data
We can choose to process data in memory or write the output to disk. When dealing with small raster object, it is safe to process and save everything in memory. However, it is strongly advised to write data to disk everytime a function is called especially with larger datasets. Writing raster data to disk can be done with the function `raster::writeRaster` taking as arguments at least the name of the raster object and its full output filename (including path and optionally extension type). Whenever calling a function of FOSTER returning a raster object, the `filename` can be provided directly in the function call and `writeRaster` will be automatically used to save the output to disk. The functions also usually supports `...` arguments where additional parameters controlling `writeRaster` can be provided (e.g. `overwrite` to overwrite existing files, `format` to specify the output file type if not given in filename, `bylayer` to write each layer of the raster object individually). 

```{r, eval=F}
#Example to write output of calcIndices to disk using different options
ind <- calcIndices(x, indices = c("NDVI","TCG","TCW"),red = 3,nir=4,filename = "full/path/to/filename.tif")
ind <- calcIndices(x, indices = c("NDVI","TCG","TCW"),red = 3,nir=4,filename = "full/path/to/filename", format="GTiff", overwrite=T, byLayer=T)
```

Whenever `filename` is kept to its default value `""` (empty character), the output raster will be processed and saved in memory if possible. If the file is too large to be processed in memory and no filename is provided, the output will be automatically written to a temp folder. The location of the temp folder and the maximum size that can be processed in memory can be found (among other options) using `rasterOptions()`. It is possible to change the global options of the `raster` package by using `rasterOptions(optionName) <- optionValue`. It is for example recommended to change the default temp directory to easily access it and clear it if necessary. 

```{r, eval=F}
rasterOptions(tmpdir) <- "path/to/tempdir"
```

#### Vector data

The function `getSample`, `getSampleValues`, `calcIndices` and `temporalMetrics` can return `SpatialPointsDataFrame` objects. These objects are usually relatively small and can be easily processed in memory. However, as for raster data, it is possible to provide the name out the output under the `filename` argument (full path to output, file extension not necessary). Only ESRI Shapefile objects are saved by FOSTER hence any other file extension provided in `filename` would be  overwritten by `.shp`

### Optimize computing times 

The functions `calcIndices`, `temporalMetrics` and `predictTrgs` support parallel processing. To enable parallel processing you need to set `par = TRUE` and the number of parallel threads `threads`. When parallel processing is performed, the input data is divided in chunks and each cluster processes a chunk at a time. For `calcIndices` and `temporalMetrics` you can specify the number of chunks each cluster will process with the argument `m` (the raster will be divided into `m x threads` blocks). 

For `predictTrgs`, controlling how data is processed is slightly different. Memory issues can occur when processing too much data at the same time because large matrices need to be stored in memory. The argument `nrows` specifies the number of rows that will be processed at a time (or per cluster when using parallel processing). By default `nrows = 1` which may not be the optimum value depending on the size of the dataset and available memory on the computer. In general, increasing `nrows` will speed up computing but also increase risks of running into memory issues. In order to choose the best value of `nrows`, it is suggested to make some test runs and monitor the memory usage of the computer to see if should be increased or decreased. 

##Description of the example

We illustrate how FOSTER can be used by imputing two ALS-derived variables: the 95th percentile of first returns height (`elev_p95`) and standard deviation of first returns height (`elev_std`). `elev_p95` and `elev_std` have been calculated on a 20 m x 20 m grid from an ALS point cloud. For this example we assume that only three ALS stripes of 500 m width and 4 km length are available. The goal is to impute these two ALS metrics on a 4km x 4 km area (extent of the multispectral data). 

We will use the following predictor variables: 

* Median, IQR and Theil-Sen slope of 25 years time series of Tasseled Cap Brightness (TCB), Greenness (TCG), Wetness (TCW) and NDVI. 
* Elevation (DEM) and terrain slope (DEM_slope)

The imputation will be based on a Random Forest k-NN model (measure of nearness based on the Random FOrest proximity matrix). 

##Input data

### ALS-derived forest attributes maps

We load `elev_p95` and `elev_std` from `.tif` files and stack them in a RasterStack object `Y_vars` using `stack()` from `raster` package
```{r}
elev_p95 <- raster(system.file("extdata/inputs/lidar/p95_lines_small.tif",package="foster"))
elev_std <- raster(system.file("extdata/inputs/lidar/std_lines_small.tif",package="foster"))
Y_vars <- stack(elev_p95,elev_std)
#Set up layers names
names(Y_vars) <- c("p95","std")
Y_vars
plot(Y_vars)
```

### Multispectral data

Multispectral data is derived from 25 years time-series (1984 - 2008) of Landsat surface reflectance composite images (30 m x 30 m resolution). We load the data from 1984 as an example: 

```{r}
spectral_1984 <- stack(system.file("extdata/inputs/spectral/Mosaic_SRef_UTM10S_1984_proxy_v2.tif",package="foster"))
names(spectral_1984) <- c("blue","green","red","nir","swir1","swir2")
spectral_1984
plot(spectral_1984)
```

### Topographic data 

Elevation (DEM) and terrain slope (DEM_slope) data are derived from the Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) global Digital Elevation Model (GDEM, v.2).Both DEM and DEM_slope were resampled to a 30 m spatial resolution and aligned with the multispectral data grid.

### Mask of forested areas

A mask of forested areas was derived from a landcover dataset of 30 m spatial resolution and aligned with multispectral data grid. Non forested cells have a `NA` value.  

```{r}
mask_forest <- raster(system.file("extdata/inputs/landcover/forested.tif",package="foster"))
plot(mask_forest)
```

##Data preparation

The first step consists in resampling `Y.vars` in order to match the spatial resolution, CRS and origin of multispectral data

```{r}
Y_vars_resampled <- matchResolution(Y_vars,spectral_1984,method='bilinear',filename='')
Y_vars_resampled
```

The response variables have now a spatial resolution of 30 m x 30 m and are aligned on the multispectral images grid.

In order to select only targets, we will need to mask reference cells (non NA values `Y_vars_resampled`) from predictor variables. Before, we need to match the extent of `Y_vars_resampled` with the study area corresponding to the extent of multispectral data. 

```{r}
#We use mask=F because we don't want to mask Y_vars_resampled with spectral_1984
Y_vars_extend <- matchExtent(Y_vars_resampled,spectral_1984,mask=F)
Y_vars_extend
```
Now we can see that `Y_vars_extend` has the same dimensions (133 rows and 134 columns) as the multispectral data 

Smoothing response and predictor variables can help reducing noise and potential spatial errors between Landsat and ALS data and improve estimation accuracy. In this example, we smooth data by assigning to each cell the mean of its 3x3 neighbors. The function `focalMultiBand` requires a weight matrix that is used to define the size of the window and weights to apply to neighboring cells. Here we use a 3x3 weight matrix with weights set to 1. Next, we provide the function that is applied to the neighboring cells values (here `mean`). Using `na.rm = T` allows mean to be calculated even if NA values occur in the neighborhood. Using `pad=T` with `padValues = T` creates additional rows and columns of NA values around the borders of `Y_vars_extend` in order to keep the original raster extent. Finally, using `keepNA = T` is useful to assign back NA values to cells that had a NA value in `Y_vars_extent` but got assigned a non-NA value when applying the spatial filter. Multispectral data will be smoothed later on, after calculating spectral indices.

```{r}
filt <- matrix(1,nrow=3,ncol=3)
Y_vars_smooth <- focalMultiBand(Y_vars_extend,w=filt,fun=mean,pad=T,padValue=NA, na.rm=T, keepNA = T, filename='')
plot(Y_vars_smooth[[1]])
```

We use the mask of forested cells to mask out cells of response variables that are not covered by forest. 

```{r, out.width="100%"}
Y_vars_mask <- matchExtent(Y_vars_smooth,mask_forest,mask=T,maskValue = NA,filename='')
plot(Y_vars_mask[[1]])
```

Finally, we select targets cells corresponding to the cells of the study area that are not covered by the ALS acquisitions and that are forested. Therefore, we can select targets cells only by masking `spectral_1984` with `Y_vars_smooth` cells that have non-NA values (using `inverse = T` argument in `matchExtent`) and by keeping forested areas only. 

```{r}
spectral_trgs <- matchExtent(spectral_1984,Y_vars_smooth, mask=T, inverse = T, filename= '')
spectral_trgs <- matchExtent(spectral_trgs, mask_forest, mask = T, maskValue = NA, filename = "")
plot(spectral_trgs[["nir"]])
```

##Stratified random sampling
Sample points need to be extracted from the ALS metrics maps in order to train and test the imputation model.To avoid selecting cells on forested edges or close to ALS extent boundaries we use `edges` to assign `NA` values to all cell located in a 3x3 neighborhood of any cells having a NA value. 

```{r}
Y_vars_edges <- edges(Y_vars_mask,w=3,filename='')
plot(Y_vars_edges[[1]])
```

In FOSTER, stratification is performed using k-means algorithm which classifies the data in clusters based on the proximity between observations. We want to extract `nSamples = 230` sample points from `nClasses = 5` strata having a minimum distance between each others of at least ` mindist = 75 ` meters. Due to the small study area of this example we have to select a relatively low number of samples and set a low `mindist` requirement. However, it is advised to increase the number of sample points and use a larger mindist to reduce spatial autocorrelation within the samples. We use `norm = T` to normalize variables prior to k-means clustering. Since we use `xy = T` the output is a SpatialPointsDataFrame with x and y coordinates added as fields. 

```{r}
nSamples = 230
nClasses = 5
mindist = 75

set.seed(1234) #For example reproducibility
samples <- getSample(Y_vars_edges, layers = c("p95","std"), n = nSamples, strata = nClasses, mindist = mindist, norm = T,xy = T,sp=T)
samples_points <- samples$samples
samples_points
```

We can plot the clustered raster and `samples` to see where samples have been selected

```{r}
plot(samples$cluster$map)
plot(samples_points,add=T)
```

##Calculate spectral indices from multispectral data

The function `calcIndices` is used to calculate spectral indices from either raster or point data. The user needs to provide the list of indices to calculate under `indices`. When tasseled cap indices are calculated, the name of the satellite that acquired the data has to be provided under `sat` and the bands have to be ordered in a specific order as explained in the documentation of `RStoolbox::tasseledCap` (bands 1, 2, 3, 4, 5, 7 for Landsat5TM). For other spectral indices, the index (layer number in the stack) of the bands corresponding to the `blue`, `green`, `red`, `nir`, `swir1`, `swir3` should be provided. 

We calculate spectral indices on the entire study area from the multispectral data. NDVI requires `red` and `nir` only. 

```{r}
ind_list <- c("TCB","TCW","TCG",'NDVI')
ind <- calcIndices(spectral_trgs,indices = ind_list, sat="Landsat5TM", red=3, nir=4)
plot(ind[["TCG"]])
```

Once indices have been calculated we can smooth them, assigning to each cell the mean of the neighboring 3x3 cells 

```{r}
ind_smooth <- focalMultiBand(ind,w=filt,fun=mean,na.rm=T,pad = T,keepNA = T)
plot(ind_smooth[["TCG"]])
```

##Summarize time series of spectral indices

`temporalMetrics` requires the name of a function that returns summary metrics of a numeric vector (e.g mean, standard deviation). The default function calculating used by `temporalMetrics` returns the median, IQR and Theil-Sen slope. However, the user can also define another function that returns metrics specific to its needs. For this example we create the function `funSummary` that returns the same metrics as the default function. When creating your own function don't forget to handle the cases where NA values might occur (by setting the `na.rm` argument to `TRUE` or `FALSE`). 

```{r}
funSummary <- function(x){
  
  c(
    median = median(x,na.rm=T),
    IQR = IQR(x,na.rm=T),
    slope = as.numeric(wql::mannKen(x)[1])
  )
}
```

In order to calculate temporal summary metrics we provide the raster `NDVI_25years.tif` that contains 25 bands corresponding to 25 years of NDVI over the entire study area. 

```{r}
NDVI_series <- stack(system.file("extdata/inputs/indices_stack/all_NDVI_stack.tif",package="foster"))
names(NDVI_series) <- paste0("NDVI_",as.character(seq(1984,2008,1)))
NDVI_series

ind_metrics <- temporalMetrics(NDVI_series,metrics='funSummary', prefix = "NDVI", filename = '')
ind_metrics
plot(ind_metrics[["NDVI_median"]])
```

The functions `temporalMetrics` and `calcIndices` support both `raster` and `spatialPointsDataFrame` objects as inputs. We illustrate that with the function `temporalMetrics`: calculating temporal metrics on the entire study area and extracting the values at samples is equivalent to extracting multispectral data  at samples and calculating temporal metrics at samples only. When experimenting with different predictors during model development, it is recommended to use the second approach which is much faster. Wall-to-wall predictors only need to be calculated for the imputation at targets. 

```{r}
#Extract values of ind_metrics at samples
ind_metrics_sample <- getSampleValues(ind_metrics,samples_points)

#Extract values of NDVI_series at samples and calculate temporal metrics at samples only
NDVI_series_samples <- getSampleValues(NDVI_series, samples_points)
NDVI_metrics_sample <- temporalMetrics(NDVI_series_samples,metrics="funSummary",filename='') 

#Compare the two objects 
head(ind_metrics_sample)
head(NDVI_metrics_sample)
```

##Train a k-NN model

Once all predictor variables at samples have been calculated and response variables at samples extracted, we have all the data necessary to train a k-NN model using `findNN`. The response and the predictor variables need to be combined in the same table. To combine two `SpatialPointsDataFrame` with the same length and where each row corresponds to the same observation we can use `cbind` as for any `data.frame` object. Four separate shapefiles corresponding to the values of the response and predictor variables at samples are provided for this example. These shapefile were created using `getSampleValues`. 

```{r}
Y_vars_samples <- rgdal::readOGR(system.file("extdata/inputs/ref_table/Y_vars_sample.shp",package = "foster"),verbose=F)
ind_metrics_samples <- rgdal::readOGR(system.file("extdata/inputs/ref_table/ind_metrics_sample.shp",package = "foster"),verbose=F)
dem_samples <- rgdal::readOGR(system.file("extdata/inputs/ref_table/dem_sample.shp",package = "foster"),verbose=F)
slope_samples <- rgdal::readOGR(system.file("extdata/inputs/ref_table/slope_sample.shp",package = "foster"),verbose=F)

samples_all <- cbind(Y_vars_samples,ind_metrics_samples,dem_samples,slope_samples)
names(samples_all) <- c("p95","std","TCG_median","TCG_IQR","TCG_slope","TCW_median","TCW_IQR","TCW_slope","TCB_median","TCB_IQR","TCB_slope","NDVI_median","NDVI_IQR","NDVI_slope","DEM", "DEM_slope")
```

From now on, we will work with regular `data.frame` object instead of `SpatialPointsDataFrame`. The function `spdf2df` easily converts a `SpatialPointsDataFrame` into a `data.frame`, giving the options to keep xy coordinates as variables. 

```{r}
table_all <- spdf2df(samples_all,xy = F)
head(table_all)
```
We need to keep a part of the samples apart for testing after the k-NN model has been trained. The function `partition` can be used for that purpose to split samples into training and testing sets. Three methods are implemented: `"random holdout"` where a percentage of the data randomly selected is left out for testing, `"group holdout` where the data is first grouped by quantiles and a percentage of the data within each group is left out for testing and `"kfold"` where k folds containing the same percentage of data left out for testing are created (cross-validation). 

```{r}
#Create data partition
set.seed(1234) #for example reproducibility
inTrain <- partition(samples_points$cluster,type="group holdout", p=0.75, groups=5,returnTrain = T)
head(inTrain)
```

We can then train a random forest (RF) k-NN model specifying the method `randomForest` and optionally setting up the number of trees and the number of parameters `mtry` evaluated at each nodes of the RF trees. We consider only the nearest neighbor by setting up `k = 1`. If we supply samples that should go to training, `findNN` returns a data.frame with observed and predicted variables of observations that are not in training. 
```{r}
set.seed(1234)#for example reproducibility
resp.vars <- c("p95","std")
pred.vars <- setdiff(colnames(table_all),c(resp.vars))
kNN <- findNN(x = table_all[,pred.vars],y=table_all[,resp.vars],inTrain = inTrain[,1], k = 1, method = "randomForest",ntree = 200)
```
## Accuracy assessment 

We can use the function `accuracy` to compute a few accuracy metrics 

```{r}
accuracy(reference = kNN$preds$obs, estimate = kNN$preds$preds, by = kNN$preds$variable)

```

The function `scatter` can be used to create a scatterplot of the predicted against observed values of the testing set

```{r}
preds_p95 <- dplyr::filter(kNN$preds,variable=="p95")
scatter(x=preds_p95$preds,y = preds_p95$obs)

preds_std <- dplyr::filter(kNN$preds,variable=="std")
scatter(x=preds_std$preds,y = preds_std$obs)
```

We can also get the most important variables of the RF-based kNN model and plot them in a boxplot or in a heatmap 

```{r}
imp <- varImp(kNN$model,scaled=F,plot=TRUE,plotType="boxplot")
imp$plot
imp <- varImp(kNN$model,scaled=T,plot=TRUE,plotType="grid")
imp$plot
```

##Impute response variables at targets

Once the k-NN model has been trained and all predictor variables have been calculated at targets, we can impute response variables at targets using `predictTrgs`. This function requires the trained model and a raster where each layer is one of the model predictor variable. Name of layers should exactly match the name of the predictor variables used during training. It returns one raster layer per response variable and another raster layer showing the nearest neighbor of each target cell (identified by the rownames of the `table_all` observations used for training). 

The stacked raster composed of the predictor variables at targets is already given for this example

```{r}
X_trgs <- stack(system.file("extdata/inputs/X_trgs/X_trgs.tif",package="foster"))
names(X_trgs) <- c("TCG_median","TCG_IQR","TCG_slope","TCW_median","TCW_IQR","TCW_slope","TCB_median","TCB_IQR","TCB_slope","NDVI_median","NDVI_IQR","NDVI_slope","DEM","DEM_slope")

X_trgs

Y_imputed <- predictTrgs(model=kNN$model,x=X_trgs,nrows = nrow(X_trgs))
Y_imputed
```

A raster object with 3 layers is returned: the first layer corresponds to the imputed "elev_p95", the second layer to "elev_std" and the last one to the ID of each reference the response variables have been imputed from. 

```{r}
plot(Y_imputed$p95)
plot(Y_imputed$std)
plot(Y_imputed$nnID1,col=rainbow(length(unique(Y_imputed$nnID1)))) #There are 171 unique values corresponding to 171 training samples used for imputation 
```
